# 0 前言

无论是双十一购物还是 12306 抢票，秒杀场景已随处可见。简单来说，秒杀就是在同一时刻大量请求争抢购买同一商品并完成交易的过程。从架构视角来看，**秒杀系统本质是一个高性能、高一致、高可用的三高系统**。

**“秒杀”的业务和行业背景**

2019年阿里巴巴双11，订单峰值达到54.4 万笔/秒，是2009年第一次双十一的1360倍

2019年京东618，18日0点-1点接待量峰值达到46.9万次

# 1 业务特点

1. **服务承载的访问压力大**
   - 瞬时流量突增：业务促销活动在特定时间开启，大量用户请求等待活动开启后瞬间涌入

   - 抢购脚本带来压力：灰产通过抢购脚本薅羊毛，一方面带来额外的系统压力，另一方面影响抢购活动公平性

   - DDOS趁虚而入：可能存在竞对在活动期间使用DDOS攻击网站

   > 分布式拒绝服务（DDoS）攻击是通过大规模互联网流量淹没目标服务器或其周边基础设施，以破坏目标服务器、服务或网络正常流量的恶意行为
2. **存在明显的访问热点**
   - 热点集中：少量优惠力度大的商品成为抢购热点，比如小米华为手机，10万台手机在1分钟内售罄

   - 热点未知：部分商家和商品可能并不在预计的促销范围内，但是可能突然成为爆款
3. **数据一致性要求高**

   - 一方面优惠商品库存有限，超卖会给商家带来损失；
   - 另一方面用户抢到商品后如果不能支付，则会引起客诉

# 2 整体思考

对于一个日常平稳的业务系统，如果直接开通秒杀功能的话，往往会出现很多问题：

| 干系人 | 问题分类   | 业务出现的问题                                               | 设计要求 |
| :----- | :--------- | :----------------------------------------------------------- | :------- |
| 用户   | 体验较差   | 秒杀开始，系统瞬间承受平时数十倍甚至上百倍的流量，直接宕掉   | 高性能   |
|        |            | 用户下单后却付不了款，显示商品已经被其他人买走了             | 一致性   |
| 商家   | 商品超卖   | 100 件商品，却出现 200 人下单成功，成功下单买到商品的人数远远超过活动商品数量的上限 | 一致性   |
|        | 资金受损   | 竞争对手通过恶意下单的方式将活动商品全部下单，导致库存清零，商家无法正常售卖 | 高可用   |
|        |            | 秒杀器猖獗，黄牛通过秒杀器扫货，商家无法达到营销目的         | 高可用   |
| 平台   | 风险不可控 | 系统的其它与秒杀活动不相关的模块变得异常缓慢，业务影响面扩散 | 高可用   |
|        | 拖垮网站   | 在线人数创新高，核心链路涉及的上下游服务从前到后都在告警     | 高性能   |
|        |            | 库存只有一份，所有请求集中读写同一个数据，DB出现单点         | 高性能   |

# 3 “秒杀”系统的技术挑战与架构优化

“秒杀”系统的建设需要整个系统从前到后全栈的协同配合，其中包含了多个基础服务，比如CDN、高防IP、容器平台、缓存、数据库、中间件、全链路压测、监控系统等

## 3.1 前端与接入层：加速与限流

**前端动静分离**，把90%的静态数据缓存在用户端或者CDN上，当真正秒杀时用户只需要点击特殊的按钮“刷新抢宝”即可，而不需要刷新整个页面，这样**只向服务端请求很少的有效数据，而不需要重复请求大量静态数据**。

网站负载均衡层或业务网关层需要能够对访问请求**按用户粒度进行流量限制**，以降低抢购脚本对系统带来的压力。

在安全方面，通过高防CDN或高防IP，降低DDOS攻击的影响。

在业务方面，通过引入**答题环节**，将突然涌入的压力平滑到3s左右的时间段内。

## 3.2 业务层：隔离、限流与弹性伸缩

通过对后台系统的微服务化改造和数据库层面的拆分（SOA），实现微服务之间的**隔离**，避免相互影响，实现不同核心服务相互独立的容量评估和紧急情况下的**限流熔断**。

在活动进行过程中，如果业务流量过大，业务需要紧急扩容，底层容器服务需要能够支持分钟内的**快速弹性扩容**，因此容器调度、镜像分发、服务发现的效率都需要相应的进行提升和优化。

在处理业务弹性扩容的过程中，还有一点也需要考虑到，即数据库的连接数风险，在没有类似dbproxy（数据库代理中间件）这样的服务进行连接池收敛的情况下，业务的弹性扩容能力需要考虑数据库的对连接数的承载力。

## 3.3 缓存层：数据读取加速

在抢购业务中，对商品库存数量的更改主要通过数据库进行，但是由于读取流量过大，一般需要通过两级缓存的机制进行优化，即：

```
Java服务进程内本地缓存-->分布式缓存服务-->数据库服务
```

由于库存数据更新非常频繁，再加上后面要提到的库存拆分设计，缓存一致性在系统设计时是需要折中考虑的，库存数据的缓存往往被设计为延后定时刷新，而不是在每次成功扣减库存后去刷新，用户可能会看到商品仍有剩余库存，但是实际下单时返回售罄；更进一步甚至可以像12306那样只缓存“有余票”或“没有余票”两个状态。

## 3.4 数据层：数据库并发扣减库存

先简单介绍扣减库存在数据库上操作的例子，SQL可以抽象为这种形式：`update stock_table set inventory=inventory-1 where item_id=xxxx and inventory>0;` **即指定商品ID（item_id），并判断库存充足情况下，扣减库存**，隔离级别大于等于`Read Committed`的关系数据库可以保证这条语句执行的原子性。在处理对少量热点商品高并发扣减库存的业务时，关系数据库都会面临如下几个难题：

1. **并发冲突代价**：当前主流的关系数据库，无论是老牌商业产品Oracle、流行开源项目MySQL、还是国产开源新秀TiDB，它们都使用经典的WAL（write ahead log）方式来实现数据的持久化，即在事务提交时保证被更新的数据（WAL）写到硬盘后，才能给客户端返回成功。而硬盘写入的latency比内存操作大几个数量级，为了优化性能，大家都引入了组提交机制（group commit），即将同时提交的多个事务的数据，合并为一条WAL写入硬盘，对于每个事务来说，latency还是一次硬盘写入IO的耗时，但是对于整个系统来说，可以将TPS从原来与硬盘IOPS相近的水平，提升几倍甚至几十倍。

   但是并不是所有的并发事务都能够合并成组提交，**如果两个事务之间存在冲突（比如并发修改同一行），那么无论是基于悲观锁进行并发控制的Oracle/MySQL，还是基于乐观锁进行并发控制的TiDB，对于相互冲突的事务，他们本质上的处理方式，都只能是排队执行，即后一个事务要等前一个事务提交完成后才能执行**。使用扣减库存的SQL举例如下：

   ```
   找到并对商品记录加锁  -->  判断库存余额  -->  修改库存余额  -->  提交WAL写盘  -->  释放锁
   ```

   <span style="color:red">针对同一个热点商品的多个并发事务，在上面加锁和释放锁之间的这段操作是无法做到并发执行的，因此在不引入任何优化的情况下，**在同一个数据表中针对一个热点商品扣减库存TPS的天花板就是硬盘的IOPS**，而在大量并发事务都在争抢行锁的情况下，情况会进一步恶化，较高的系统负载，叠加上锁冲突检测等额外代价，可能造成系统的整体吞吐降低至个位数</span>。

2. **可能存在超卖风险**：考虑到上述并发事务提交WAL的问题，在实际系统上，为了降低写WAL的latency，保证系统吞吐，一般会将写硬盘和同步备机调整为异步方式，而这个调整又会带来新的问题，即主库宕机情况下的数据不一致，主库重启或者备库切换为主库后，可能存在宕机前部分WAL没有被持久化的风险，反映到扣减库存的逻辑上就是已经被扣减的库存又被恢复了回来，最终在业务上形成超卖

3. **复杂事务恶化冲突**：上面所举的例子是单行事务的update，行锁的临界区（“找到并对商品记录加锁  -->  判断库存余额  -->  修改库存余额  -->  提交WAL写盘  -->  释放锁”）都在数据库处理的边界之内，但是在某些复杂场景下，在库存扣减的事务中可能存在多条语句的情况，比如**扣减库存（update）+生成订单（insert）**在一个事务内完成，**这种情况下行锁的临界区扩大到受业务网络交互的影响，整体冲突加剧、吞吐进一步降低**。

<span style="color:red">数据库层面对于并发扣减库存的优化思路</span>：

1. **库存拆分**：<span style="color:red">在业务层将同一个商品的库存记录拆分为多行甚至多个表里面去，降低在同一行或同一个数据表上的并发冲突，比如针对业务请求中的userid计算hash取模后确定要扣减哪个库存记录</span>。这个方案能够很大程度的降低并发冲突，不需要数据库内核配合做修改，是行业内的主流方案，<span style="color:blue">它的问题是：同一个商品不同库存记录的扣减速度不均衡（热点商品往往在几十秒内被强光，这个不均衡问题并不严重），给总库余额计数带来的复杂度，业务需要预先感知热点商品并且针对性的进行库存拆分</span>。
2. **批处理**：**通过修改数据库内核代码，将相互冲突的事务，合并为一个事务**或者一次WAL组提交，**达到批处理的效果**，**AliSQL的做法是在MySQL server层识别这类update语句，将它们解析后合并成为一条SQL再执行**，比如10个扣减库存语句，合并为一个扣减库存的语句一次性扣减数量为10，这个做法的优势是对数据库内核代码修改不多、复杂度可控，局限是只能在特定语句的基础上进行优化，没有比较好的普适性；OceanBase则选择了另外一个优化思路，即提前释放锁，在事务确定要提交（比如单行事务执行成功或者用户在事务最后一条语句上标记“Commit on success”）的情况下，不需要等WAL同步，而先把事务涉及的行锁先释放掉，这样可以使得其他并发事务能够进入临界区，最终效果可以达到对同一行修改的多个并发事务的WAL，可能在一次组提交内完成。
3. **请求排队**：即使我们在数据库内核层面引入了上述“批处理”的优化，**对热点行的并发扣减库存业务仍然会面临多个事务并发争抢进入临界区的情况，并发等锁的事务会占据宝贵的连接和线程资源，系统负载可能持续恶化**；这里的一个优化思路是，在数据库内核层面将并发扣减同一个商品库存的事务排到一个队列处理（比如让用户在SQL注释上标记这个事务划分队列的依据，一般来说可以用商品ID取模），降低并发冲突，减少对连接和线程资源的占用，降低系统负载。这个优化目前已经在AliSQL上开源，效果还是比较明显的。
4. **存储过程或类似命令**：对于一个事务里要执行多条语句的情况，会造成临界区的扩大，严重影响并发度，一个最有效的方案是数据库层面支持存储过程，多个语句放在存储过程里一次性提交给数据库；但是MySQL并不支持存储过程，因此可以针对具体场景引入一些类似存储过程的优化，当然核心仍然是将一个事务中的多条语句合并，实现与数据库在一次交互中完成。比如AliSQL的Commit on success，可以用在扣减库存+生成订单的场景中，即开启事务后先执行几乎没有并发冲突的`insert`语句生成订单，然后带上Commit on success标记执行扣减库存命令，库存扣减成功后就立即提交事务，不需要等待客户端再发`commit`，这样一来热点行冲突的临界区仍然与单行事务一样了。再比如OceanBase引入的... when row_affected()语法，允许在一个语句内先执行update，然后根据受影响的函数来决定事务执行其他修改，这已经很像存储过程了。

## 3.5 业务架构：减库存与生成订单一致性

在上面的例子中，扣减库存与生成订单的事务是在同一个数据库实例完成的，但是随着业务的拆分、业务逻辑的变化，扣减库存与生成订单可能被拆到不同的服务中去，那么**如何保证扣减库存与生成订单的一致性**，也成为一个有挑战的问题。

需要注意的是这种场景下，产生的数据不一致，不会造成商品超卖，而是会造成用户下单成功，却看不到待支付订单。

针对这类问题，一般通过DRC/DTS这类中间件来配合实现数据一致性，即扣减库存成功后，MySQL就会有相应的binlog，DRC/DTS订阅库存中心的binlog，订单中心再根据DRC/DTS订阅的数据来生成订单。因为MySQL binlog有多份副本不会丢失，所以即使订单中心出现超时抖动等问题，在恢复正常后，就能够继续生成订单。当然，引入这类优化后，也意味着系统要进行异步化改造，因为生成订单的逻辑本质上变成了异步操作。

## 3.6 技术保障

- **业务全链路压测**

全链路压测是阿里2013年在双11压力之下被逼出来的技能，由于线上线下环境多少都会有些不同，很多问题只有在实际生产环境才能暴露，对于秒杀类业务，线上压测也能够实际评估出系统的真实承载力，为容量预估给出重要参考。

阿里的全链路压测是真正的“全链路”，淘宝、天猫、支付宝的系统都会一同参与。

- **准实时监控**

这里的技术挑战主要是在海量业务和数据库的场景下，如何做到全局有效而实时的监控数据采集和分析，一方面是为了实时监控系统健康度，另一方面则是pr需求。

- **实时热点发现**

与准实时的监控类似，技术团队需要及时发现系统中的热点和瓶颈，并作出调整。实时热点的发现，需要业务层监控、数据库层监控一起配合改进优化，才能准确分析出热点。

- **容灾与高可用**

业务容器宕机、数据库主库宕机、机房级宕机都可能出现，技术团队需要通过有效的容灾规划、set化、分库分表等，降低“爆炸半径”，并且要做到快速切换。

因此这里的技术挑战是容器的快速扩容，容器镜像快速分发，数据库分库分表尽量降低单个集群主备切换的影响，业务层面的set化和灵活的流量切换。

- **系统预热**

大量流量会在大促开始的第0秒集中涌入，活动开始前需要完成 **JVM预加载代码、缓存预热、数据库连接池预热**等系统预热工作。

同时在各个系统的设计时也要做到避免对单点的依赖，原则仍然是降低“爆照半径”，防止大量流量进入后，把系统中的某个单点压垮，造成整个系统的风暴。

# 4 一致性

秒杀系统中，库存是个关键数据，卖不出去是个问题，超卖更是个问题。**秒杀场景下的一致性问题，主要就是库存扣减的准确性问题**。

## 4.1 减库存的方式

电商场景下的购买过程一般分为两步：下单和付款。“提交订单”即为下单，“支付订单”即为付款。基于此设定，减库存一般有以下几个方式：

1. 下单减库存。买家下单后，扣减商品库存。下单减库存是最简单的减库存方式，也是控制最为精确的一种
2. 付款减库存。买家下单后，并不立即扣减库存，而是等到付款后才真正扣减库存。但因为付款时才减库存，如果并发比较高，可能出现买家下单后付不了款的情况，因为商品已经被其他人买走了
3. **预扣库存**。这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如 15 分钟），超过这段时间，库存自动释放，释放后其他买家可以购买

能够看到，减库存方式是基于购物过程的多阶段进行划分的，但无论是在下单阶段还是付款阶段，都会存在一些问题，下面进行具体分析。

## 4.2 减库存的问题

### 4.2.1 下单减库存

优势：用户体验最好。下单减库存是最简单的减库存方式，也是控制最精确的一种。下单时可以直接通过数据库事务机制控制商品库存，所以一定不会出现已下单却付不了款的情况。

劣势：可能卖不出去。正常情况下，买家下单后付款概率很高，所以不会有太大问题。但有一种场景例外，就是当卖家参加某个促销活动时，竞争对手通过恶意下单的方式将该商品全部下单，导致库存清零，那么这就不能正常售卖了——要知道，**恶意下单的人是不会真正付款的，这正是 “下单减库存” 的不足之处**。

### 4.2.2 付款减库存

优势：一定实际售卖。“下单减库存” 可能导致恶意下单，从而影响卖家的商品销售， “付款减库存” 由于需要付出真金白银，可以有效避免。

劣势：用户体验较差。用户下单后，不一定会实际付款，假设有 100 件商品，就可能出现 200 人下单成功的情况，**因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况**，这尤其会发生在大促的热门商品上。如此一来**就会导致很多买家下单成功后却付不了款**，购物体验自然是比较差的。

### 4.2.3 预扣库存

优势：缓解了以上两种方式的问题。预扣库存实际就是“下单减库存”和 “付款减库存”两种方式的结合，将两次操作进行了前后关联，下单时预扣库存，付款时释放库存。

劣势：并没有彻底解决以上问题。比如针对恶意下单的场景，虽然可以把有效付款时间设置为 10 分钟，但恶意买家完全可以在 10 分钟之后再次下单。

### 4.2.4 小结

减库存的问题主要体现在用户体验和商业诉求两方面，其本质原因在于购物过程存在两步甚至多步操作，在不同阶段减库存，容易存在被恶意利用的漏洞。

## 4.3 实际如何减库存

业界最为常见的是**预扣库存**。无论是外卖点餐还是电商购物，**下单后一般都有个 “有效付款时间”，超过该时间订单自动释放，**这就是典型的预扣库存方案。但如上所述，预扣库存还需要解决恶意下单的问题，保证商品卖的出去；另一方面，如何避免超卖，也是一个痛点。

1. 卖的出去：恶意下单的解决方案主要还是**结合安全和反作弊措施来制止。比如，识别频繁下单不付款的买家并进行打标**，这样可以在打标买家下单时不减库存；**再比如为大促商品设置单人最大购买件数，一人最多只能买 N 件商品；又或者对重复下单不付款的行为进行次数限制阻断等**
2. 避免超卖：库存超卖的情况实际分为两种。对于普通商品，秒杀只是一种大促手段，即使库存超卖，商家也可以通过补货来解决；而对于一些商品，秒杀作为一种营销手段，完全不允许库存为负，也就是在数据一致性上，需要保证大并发请求时数据库中的库存字段值不能为负，一般有多种方案：一是在通过事务来判断，即保证减后库存不能为负，否则就回滚；二是直接设置数据库字段类型为无符号整数，这样一旦库存为负就会在执行 SQL 时报错；三是使用 CASE WHEN 判断语句——

代码块

```mysql
UPDATE item SET inventory = CASE WHEN inventory >= xxx THEN inventory-xxx ELSE inventory END
```

**业务手段保证商品卖的出去，技术手段保证商品不会超卖**，库存问题从来就不是简单的技术难题，解决问题的视角是多种多样的。

## 4.4 一致性性能的优化

库存是个关键数据，更是个热点数据。对系统来说，热点的实际影响就是 “高读” 和 “高写”，也是秒杀场景下最为核心的一个技术难题。

### 4.4.1 高并发读

秒杀场景解决高并发读问题，关键词是“分层校验”。即在读链路时，**只进行不影响性能的检查操作，如用户是否具有秒杀资格、商品状态是否正常、用户答题是否正确、秒杀是否已经结束、是否非法请求等**，而不做一致性校验等容易引发瓶颈的检查操作；直到写链路时，才对库存做一致性检查，在数据层保证最终准确性。

因此，在分层校验设定下，系统可以采用分布式缓存甚至LocalCache来抵抗高并发读。即允许读场景下一定的脏数据，这样只会导致少量原本无库存的下单请求被误认为是有库存的，等到真正写数据时再保证最终一致性，由此做到高可用和一致性之间的平衡。

实际上，分层校验的核心思想是：不同层次尽可能过滤掉无效请求，只在“漏斗” 最末端进行有效处理，从而缩短系统瓶颈的影响路径。

### 4.4.2 高并发写

高并发写的优化方式，一种是更换DB选型，一种是优化DB性能，以下分别进行讨论。

**4.4.2.1 更换DB选型**

秒杀商品和普通商品的减库存是有差异的，核心区别在数据量级小、交易时间短，因此**能否把秒杀减库存直接放到缓存系统中实现**呢，也就是直接在一个带有持久化功能的缓存中进行减库存操作，比如 Redis？

如果减库存逻辑非常单一的话，比如没有复杂的 SKU 库存和总库存这种联动关系的话，个人认为是完全可以的。但如果有比较复杂的减库存逻辑，或者需要使用到事务，那就必须在数据库中完成减库存操作。

**4.4.2.2 优化DB性能**

**库存数据落地到数据库实现其实是一行存储（MySQL），因此会有大量线程来竞争 InnoDB 行锁。但并发越高，等待线程就会越多，TPS 下降，RT 上升，吞吐量会受到严重影响**——注意，这里假设数据库已基于上文【性能优化】完成数据隔离，以便于讨论聚焦 。

解决并发锁的问题，有两种办法：

1. 应用层排队。通过缓存加入集群分布式锁，从而控制集群对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用过多的数据库连接
2. 数据层排队。应用层排队是有损性能的，数据层排队是最为理想的。业界中，阿里的数据库团队开发了针对InnoDB 层上的补丁程序（patch），可以基于DB层对单行记录做并发排队，从而实现秒杀场景下的定制优化——注意，排队和锁竞争是有区别的，如果熟悉 MySQL 的话，就会知道 InnoDB 内部的死锁检测，以及 MySQL Server 和 InnoDB 的切换都是比较消耗性能的。另外阿里的数据库团队还做了很多其他方面的优化，如 COMMIT_ON_SUCCESS 和 ROLLBACK_ON_FAIL 的补丁程序，通过在 SQL 里加入提示（hint），实现事务不需要等待实时提交，而是在数据执行完最后一条 SQL 后，直接根据 TARGET_AFFECT_ROW 的结果进行提交或回滚，减少网络等待的时间（毫秒级）。目前阿里已将包含这些补丁程序的 MySQL 开源：[AliSQL](https://github.com/alibaba/AliSQL?spm=a2c4e.10696291.0.0.34ba19a415ghm4)

### 4.4.3 小结

高读和高写的两种处理方式大相径庭。读请求的优化空间要大一些，而写请求的瓶颈一般都在存储层，优化思路的本质还是基于 CAP 理论做平衡。

# Reference

- 铁路12306网站资料：
  - [知乎回答：12306 能扛得住明星出轨这种流量冲击吗？](https://www.zhihu.com/question/308463476/answer/569452666)
  - [酷壳：由12306.CN谈谈网站性能技术](https://coolshell.cn/articles/6470.html)
- 阿里双11资料：
  - [淘宝大秒杀系统设计详解](https://juejin.im/post/5bb05d786fb9a05d1d2e1e68)
  - [张瑞：一个阿里技术男经历的六年“双11”：技术改变阿里](https://www.huxiu.com/article/270730.html)
- 理解大促商业逻辑：[知乎文章：透过热闹看本质——如何理解天猫双11](https://zhuanlan.zhihu.com/p/53648752)
- AliSQL：
  - GitHub：https://github.com/alibaba/AliSQL/wiki/AliSQL-Performance-benchmark-for-inventory
- 什么是DDoS攻击？
  - https://www.cloudflare.com/zh-cn/learning/ddos/what-is-a-ddos-attack/